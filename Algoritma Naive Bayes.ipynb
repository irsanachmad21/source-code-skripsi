{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["g9Texe8ONig6","TZM8NdpqNta1","nSyG9vOkgmXc","PFLH9R4moJ9v","Sr1ATl9hwQqz"],"authorship_tag":"ABX9TyNTJ86NIU7haYnbivkcv6ke"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ***LABELING DATA***"],"metadata":{"id":"g9Texe8ONig6"}},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv(\"hasil_preprocessing.csv\")\n","data.info()"],"metadata":{"id":"h-oD9Ov0NpvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = data.dropna()\n","df.info()"],"metadata":{"id":"BLlkPOceOSP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.DataFrame(df[['steming_data']])\n","data.head(5)"],"metadata":{"id":"BMevbCOCOstm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# fungsi untuk menentukan sentimen dan menghitung skor sentimen\n","def determine_sentiment(text):\n","  positive_count = sum(1 for word in text.split() if word in positive_lexicon)\n","  negative_count = sum(1 for word in text.split() if word in negative_lexicon)\n","  score = positive_count - negative_count # hitung skor sentimen\n","  if score >= 0:\n","    sentiment = \"Positif\"\n","  elif score < 0:\n","    sentiment = \"Negatif\"\n","  else:\n","    sentiment = None\n","  return sentiment, score\n","\n","# baca kamus leksikon positif dan negatif\n","positive_lexicon = set(pd.read_csv(\"Positive.tsv\", sep=\"\\t\", header=None)[0])\n","negative_lexicon = set(pd.read_csv(\"Negative.tsv\", sep=\"\\t\", header=None)[0])\n","\n","# fungsi untuk mengganti nilai None pada sentiment\n","def replace_none_sentiment(sentiments):\n","  replace_flag = \"Positif\"\n","  for i in range(len(sentiments)):\n","    if sentiments[i] is None:\n","      sentiments[i] = replace_flag\n","      replace_flag = \"Negatif\" if replace_flag == \"Positif\" else \"Positif\"\n","  return sentiments\n","\n","# terapkan fungsi determine_sentiment untuk mendapatkan kolom Sentiment dan Sentiment_Score\n","data[['Sentiment', 'Score']] = data['steming_data'].apply(lambda x: pd.Series(determine_sentiment(x)))\n","\n","# ganti nilai None pada kolom Sentiment\n","data['Sentiment'] = replace_none_sentiment(data['Sentiment'].tolist())\n","\n","df = pd.DataFrame(data[['steming_data', 'Score', 'Sentiment']])\n","df.head(5)\n","\n","# tampilkan hasilnya\n","df.head()"],"metadata":{"id":"yGrCLsFzPMaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = df['Sentiment'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(6,4))\n","ax = sns.barplot(\n","    x=sentiment_count.index,\n","    y=sentiment_count.values,\n","    hue=sentiment_count.index,\n","    palette='pastel',\n","    legend=False\n",")\n","plt.title('Labeling Data', fontsize=14, pad=20)\n","plt.xlabel('Class Sentiment', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(df['Sentiment'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","plt.show()"],"metadata":{"id":"Ro0WrL0kSpFj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv('hasil_labeling.csv', encoding='utf8', index=False)"],"metadata":{"id":"VtsKTyk6VBp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# eksport ke file csv terpisah berdasarkan label sentimen\n","for sentiment_label in ['Positif', 'Negatif']:\n","  # filter data sesuai dengan label sentimen\n","  filtered_data = df[df['Sentiment'] == sentiment_label]\n","\n","  # tentukan nama file berdasarkan label sentimen\n","  filename = f\"{sentiment_label}_dataset.csv\"\n","\n","  # eksport data yang telah difilter ke file csv\n","  filtered_data.to_csv(filename, index=False)"],"metadata":{"id":"zTrwsTx4VOP-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**WORD CLOUD**"],"metadata":{"id":"ZTU-4zF0WMjv"}},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv(\"hasil_labeling.csv\")\n","data.head(5)"],"metadata":{"id":"A3r9acikWRVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","\n","# pisahkan dataset berdasarkan sentimen\n","sentimen_Negative = data[data['Sentiment'] == 'Negatif']['steming_data'].str.cat(sep=' ')\n","sentimen_Positive = data[data['Sentiment'] == 'Positif']['steming_data'].str.cat(sep=' ')"],"metadata":{"id":"dVfbdTDMWnHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fungsi untuk membuat dan menampilkan WordCloud\n","def create_wordcloud(text, title):\n","  wordcloud = WordCloud(width=800, height=400, random_state=42, max_font_size=100, background_color='white').generate(text)\n","\n","  plt.figure(figsize=(10, 5))\n","  plt.imshow(wordcloud, interpolation='bilinear')\n","  plt.axis('off')\n","  plt.title(title)\n","  plt.show()"],"metadata":{"id":"6a9r0fCdXNnr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# membuat WordCloud untuk sentimen negatif\n","create_wordcloud(sentimen_Negative, \"Word Cloud Sentimen Negatif\")"],"metadata":{"id":"Mx2NclAxYJQR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# membuat WordCloud untuk sentimen positif\n","create_wordcloud(sentimen_Positive, \"Word Cloud Sentimen Positif\")"],"metadata":{"id":"zlX4JNqbYbqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","\n","text = ' '.join(data['steming_data'].apply(lambda x: str(x) if isinstance(x, (str, int, float)) else ' '))\n","wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n","\n","plt.figure(figsize=(10, 5))\n","\n","# menampilkan word cloud dengan interpolasi gambar bilinear\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"DGcn3hXFYte5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***SPLITTING DATA***"],"metadata":{"id":"TZM8NdpqNta1"}},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv(\"hasil_labeling.csv\")\n","data.info()"],"metadata":{"id":"DsWvB9pHZ95I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.dropna()"],"metadata":{"id":"xkPJrQVDcCsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"K4PyOE0VcGmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# bagi data menjadi data training dan data testing\n","X_train, X_test, y_train, y_test = train_test_split(df['steming_data'], df['Sentiment'], test_size=0.2, random_state=42)"],"metadata":{"id":"E4YDuo-ccLGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# simpan data latih ke file csv\n","train_set = pd.DataFrame({'text': X_train, 'sentiment': y_train})\n","train_set.to_csv('train_data.csv', index=False)"],"metadata":{"id":"CU7DvQzXc2w-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# simpan data uji ke file csv\n","test_set = pd.DataFrame({'text': X_test, 'sentiment': y_test})\n","test_set.to_csv('test_data.csv', index=False)"],"metadata":{"id":"yjG1an6WdXnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# menampilkan informasi jumlah data\n","print(f'Jumlah Data Latih: {len(X_train)}')\n","print(f'Jumlah Data Uji: {len(X_test)}')"],"metadata":{"id":"VMBrOhfPdrYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# jumlah data latih dan data uji\n","train_size = len(X_train)\n","test_size = len(X_test)\n","\n","# membuat plot\n","plt.figure(figsize=(6, 4))\n","bars = plt.bar(['Data Latih', 'Data uji'], [train_size, test_size], color=['#B0CBEF', '#F4B183'])\n","\n","# menambahkan label untuk setiap bar (dalam kurung persentasi)\n","for bar in bars:\n","  height = bar.get_height()\n","  plt.text(bar.get_x() + bar.get_width()/2, height + 20, f'{height} ({height / (train_size + test_size) * 100:.2f}%)', ha='center', va='bottom')\n","\n","plt.title(\"Splitting Data\")\n","plt.xlabel('Jenis Data')\n","plt.ylabel('Jumlah Data')\n","plt.show()"],"metadata":{"id":"e1oJ0IPZd8dp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***NAIVE BAYES CLASIFICATION***"],"metadata":{"id":"nSyG9vOkgmXc"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"5vFfz9jJgu5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"g3GClHGtg20j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Transformasi Teks Menjadi Matrik Frekuensi Token Menghitung Probabilitas Prior (P(C)P(C))**"],"metadata":{"id":"SB4QMlsIg7W5"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# inisialisasi CountVectorizer\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(df['steming_data'])\n","features = vectorizer.get_feature_names_out()\n","df_tokens = pd.DataFrame(X.toarray(), columns=features)\n","df_combined = pd.concat([df_tokens, df['Sentiment']], axis=1)\n","\n","# menghitung frekuensi token untuk setiap sentimen\n","frequency_positive = df_combined[df_combined['Sentiment'] == 'positif'].drop('Sentiment', axis=1).sum()\n","frequency_negative = df_combined[df_combined['Sentiment'] == 'negatif'].drop('Sentiment', axis=1).sum()\n","\n","# menghitung probabilitas prior\n","sentiment_counts = df['Sentiment'].value_counts()\n","total_samples = len(df)\n","prior_probabilities = sentiment_counts / total_samples\n","\n","print(\"Prior Probabilities:\")\n","print(prior_probabilities)"],"metadata":{"id":"u77Vei7Xg45W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menghitung Probabilitas Kondisional (P(wi|C)P(w i|C))**"],"metadata":{"id":"6n8c-Dpbj1DE"}},{"cell_type":"code","source":["# menghitung probabilitas kondisional dengan smoothing Laplace\n","\n","total_positive = frequency_positive.sum()\n","total_negative = frequency_negative.sum()\n","\n","probability_conditional_positive = (frequency_positive + 1) / (total_positive + len(features))\n","probability_conditional_negative = (frequency_negative + 1) / (total_negative + len(features))\n","\n","print(\"Probability Conditional Positive:\")\n","print(probability_conditional_positive)\n","print(\"Probability Conditional Negative:\")\n","print(probability_conditional_negative)"],"metadata":{"id":"HB10XLU8j3bU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menghitung Probabilitas Posterior (P(C|w)P(C|w)) untuk setiap Dokumen**"],"metadata":{"id":"Zw38cTY4mJno"}},{"cell_type":"code","source":["# menghitung probabilitas posterior untuk setiap dokumen\n","def calculate_posterior_probabilities(document):\n","  words = document.split()\n","  posterior_positive = prior_probabilities['Positif']\n","  posterior_negative = prior_probabilities['Negatif']\n","\n","  for word in words:\n","    if word in features:\n","      posterior_positive *= probability_conditional_positive[word]\n","      posterior_negative *= probability_conditional_negative[word]\n","  return {'Positif': posterior_positive, 'Negatif': posterior_negative}\n","\n","df['posterior_probabilities'] = df['steming_data'].apply(calculate_posterior_probabilities)\n","df.head()"],"metadata":{"id":"5xjmNH6Ql8d-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***NAIVE BAYES MULTINOMIAL***"],"metadata":{"id":"eFaHcyBPwEih"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"FPUBuvbYyJZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"Ehw0LhXVyKFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# preprocessing data\n","tfidf = TfidfVectorizer()\n","x = tfidf.fit_transform(df['steming_data']).toarray()\n","y = df['Sentiment']\n","\n","# split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# initialize and train model MultinomialNB\n","mnb = MultinomialNB()\n","mnb.fit(X_train, y_train)\n","\n","# predict with MultinomialLB\n","y_pred_mnb = mnb.predict(X_test)\n","\n","# evaluate MultinomialNB\n","conf_matrix_mnb = confusion_matrix(y_test, y_pred_mnb)\n","class_report_mnb = classification_report(y_test, y_pred_mnb)\n","accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n","\n","print(\"Results\")\n","print(\"=====================================\")\n","print(\"Confusion Matrix :\")\n","print(conf_matrix_mnb)\n","print(\"=====================================\")\n","print(\"\\nClassification Report :\")\n","print(class_report_mnb)\n","print(\"=====================================\")\n","print(f\"Accuracy : {accuracy_mnb:.4f}\")\n","print(\"=====================================\")\n","\n","# plot confusion matrix for MultinomialNB\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(conf_matrix_mnb, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()\n","\n","# create DataFrame for actual vs predicted (MultinomialNB)\n","results_mnb = pd.DataFrame({'steming_data': df.loc[y_test.index, 'steming_data'], 'Actual': y_test, 'Predicted': y_pred_mnb})\n","results_mnb.to_csv(\"hasil_prediksi.csv\", encoding='utf8', index=False)\n","print(\"Actual vs Predicted :\")\n","results_mnb.head()"],"metadata":{"id":"NtKAXxIgwKix"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menampilkan Jumlah Analisis Data Aktual**"],"metadata":{"id":"Pv7FRZZKzCs-"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = results_mnb['Actual'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(4, 2))\n","ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n","plt.title('Hasil Analisis Data Actual', fontsize=14, pad=20)\n","plt.xlabel('Class Actual', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(results_mnb['Actual'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","plt.show()"],"metadata":{"id":"Uv_b6pF8yP-4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menampilkan Jumlah Analisis Data Prediksi**"],"metadata":{"id":"2RH8OhYqzGPb"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = results_mnb['Predicted'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(4, 2))\n","ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n","plt.title('Hasil Analisis Data Predicted', fontsize=14, pad=20)\n","plt.xlabel('Class Predicted', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(results_mnb['Predicted'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","plt.show()"],"metadata":{"id":"YEfc46ntybNW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***NAIVE BAYES GAUSSIAN***"],"metadata":{"id":"PFLH9R4moJ9v"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"LxS1ynD7oOGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"hp-ZA1YVoZ00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# preprocessing data\n","tfidf = TfidfVectorizer()\n","x = tfidf.fit_transform(df['steming_data']).toarray()\n","y = df['Sentiment']\n","\n","# split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# initialize and train model gaussianNB\n","gnb = GaussianNB()\n","gnb.fit(X_train, y_train)\n","\n","# predict with GaussianNB\n","y_pred_gnb = gnb.predict(X_test)\n","\n","# evaluate GaussianNB\n","conf_matrix_gnb = confusion_matrix(y_test, y_pred_gnb)\n","class_report_gnb = classification_report(y_test, y_pred_gnb)\n","accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n","\n","print(\"GaussianNB Results\")\n","print(\"=====================================\")\n","print(\"Confusion Matrix (GaussianNB):\")\n","print(conf_matrix_gnb)\n","print(\"=====================================\")\n","print(\"\\nClassification Report (GaussianNB):\")\n","print(class_report_gnb)\n","print(\"=====================================\")\n","print(f\"Accuracy (GaussianNB): {accuracy_gnb:.4f}\")\n","print(\"=====================================\")\n","\n","# plot confusion matrix for GaussianNB\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(conf_matrix_gnb, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix (GaussianNB)')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()\n","\n","# create DataFrame for actual vs predicted (GaussianNB)\n","results_gnb = pd.DataFrame({'steming_data': df.loc[y_test.index, 'steming_data'], 'Actual': y_test, 'Predicted': y_pred_gnb})\n","results_gnb.to_csv(\"hasil_prediksi_gaussian.csv\", encoding='utf8', index=False)\n","print(\"Actual vs Predicted (GaussianNB):\")\n","results_gnb.head()"],"metadata":{"id":"yZonFy8foboE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menampilkan Jumlah Analisis Data Aktual**"],"metadata":{"id":"gO6WUKlSy0Np"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = results_gnb['Actual'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(4, 2))\n","ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n","plt.title('Hasil Analisis Data Actual', fontsize=14, pad=20)\n","plt.xlabel('Class Actual', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(results_gnb['Actual'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","  plt.show()"],"metadata":{"id":"IMB_dE16t2A3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menampilkan Jumlah Analisis Data Prediksi**"],"metadata":{"id":"ioKJRGTWy6Wg"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = results_gnb['Predicted'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(4, 2))\n","ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n","plt.title('Hasil Analisis Data Predicted', fontsize=14, pad=20)\n","plt.xlabel('Class Predicted', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(results_gnb['Predicted'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","  plt.show()"],"metadata":{"id":"lqTi15mfvx0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **NAIVE BAYES BERNOULLI**"],"metadata":{"id":"Sr1ATl9hwQqz"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"omYpJ2FowYaG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"EiVy7uewzXdq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# preprocessing data\n","tfidf = TfidfVectorizer()\n","x = tfidf.fit_transform(df['steming_data']).toarray()\n","y = df['Sentiment']\n","\n","# split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# initialize and train model BernoulliNB\n","brn = BernoulliNB()\n","brn.fit(X_train, y_train)\n","\n","# predict with BernoulliNB\n","y_pred_brn = brn.predict(X_test)\n","\n","# evaluate BernoulliNB\n","conf_matrix_brn = confusion_matrix(y_test, y_pred_brn)\n","class_report_brn = classification_report(y_test, y_pred_brn)\n","accuracy_brn = accuracy_score(y_test, y_pred_brn)\n","\n","print(\"BernoulliNB Results\")\n","print(\"=====================================\")\n","print(\"Confusion Matrix (BernoulliNB):\")\n","print(conf_matrix_brn)\n","print(\"=====================================\")\n","print(\"\\nClassification Report (BernoulliNB):\")\n","print(class_report_brn)\n","print(\"=====================================\")\n","print(f\"Accuracy (BernoulliNB): {accuracy_brn:.4f}\")\n","print(\"=====================================\")\n","\n","# plot confusion matrix for BernoulliNB\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(conf_matrix_brn, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix (BernoulliNB)')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()\n","\n","# create DataFrame for actual vs predicted (BernoulliNB)\n","results_brn = pd.DataFrame({'steming_data': df.loc[y_test.index, 'steming_data'], 'Actual': y_test, 'Predicted': y_pred_brn})\n","results_brn.to_csv(\"hasil_prediksi_multinomial.csv\", encoding='utf8', index=False)\n","print(\"Actual vs Predicted (BernoulliNB):\")\n","results_brn.head()"],"metadata":{"id":"8UGYb4Y1zp4l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menampilkan Jumlah Analisis Data Aktual**"],"metadata":{"id":"gz_eaqRO0Kjp"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = results_brn['Actual'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(4, 2))\n","ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n","plt.title('Jumlah Analisis Data Actual', fontsize=14, pad=20)\n","plt.xlabel('Class Actual', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(results_brn['Actual'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","  plt.show()"],"metadata":{"id":"QZz2Om6X0MKf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Menampilkan Jumlah Analisis Data Prediksi**"],"metadata":{"id":"QDRW4eIl0SKA"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sentiment_count = results_brn['Predicted'].value_counts()\n","sns.set_style('whitegrid')\n","\n","fig, ax = plt.subplots(figsize=(4, 2))\n","ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n","plt.title('Jumlah Analisis Data Predicted', fontsize=14, pad=20)\n","plt.xlabel('Class Predicted', fontsize=12)\n","plt.ylabel('Jumlah Data', fontsize=12)\n","\n","total = len(results_brn['Predicted'])\n","\n","for i, count in enumerate(sentiment_count.values):\n","  percentage = f'{100 * count / total:.2f}%'\n","  ax.text(i, count + 0.10, f'{count}\\n({percentage})', ha='center', va='bottom')\n","\n","  plt.show()"],"metadata":{"id":"Cw9ykai60Wct"},"execution_count":null,"outputs":[]}]}